import os
from dotenv import load_dotenv
from pathlib import Path

# Chargement des variables d‚Äôenvironnement
load_dotenv()

BASE_DIR = Path(__file__).resolve().parent.parent

# === OpenAI ===
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_CHAT_MODEL = "chatgpt-4o-latest"  # "gpt-4o" ou "gpt-3.5-turbo" "chatgpt-4o-latest"
OPENAI_EMBED_MODEL = "text-embedding-3-small"

# === Qdrant ===
QDRANT_URL = os.getenv("QDRANT_URL", "http://localhost:6333")
QDRANT_API_KEY = os.getenv("QDRANT_API_KEY", None)
QDRANT_COLLECTION = os.getenv("QDRANT_COLLECTION", "bofip_hybrid")
QDRANT_VECTOR_SIZE = int(os.getenv("QDRANT_VECTOR_SIZE", "1536"))

# === Fichiers ===
SOURCE_FILE = BASE_DIR / "data" / "raw" / "fiscale" / "bofip" / "bofip-vigueur.json"
OUTPUT_BIG_CHUNKS = "data/processed/bofip_chunks_bs.json"
OUTPUT_SMALL_CHUNKS = "data/processed/bofip_small_chunks.json"
SMALL_CHUNKS_JSON_PATH = BASE_DIR / "data" / "processed" / "all_small_chunks.json"
CHARTE_IA_PATH = BASE_DIR / "Charte IA" / "Charte IA.pdf"

DOCUMENT_SOURCES = {
    "code_assurances": {
        "PDF_PATH": BASE_DIR / "data" / "raw" / "juridique" / "Code_des_assurances.pdf",
        "OUTPUT_BIG_CHUNKS": BASE_DIR / "data" / "processed" / "code_assurances_chunks.json",
        "OUTPUT_SMALL_CHUNKS": BASE_DIR / "data" / "processed" / "code_assurances_small_chunks.json",
        "CHUNK_SIZE": 800,
        "CHUNK_OVERLAP": 0,
    },
}

# === Param√®tres de d√©coupage ===
CHUNK_SIZE = 800
CHUNK_OVERLAP = 0

# === S√©ries autoris√©es ===
ALLOWED_SERIES = {
    "IR", "RSA", "RPPM", "BIC", "IS", "TVA", "TCA",
    "CVAE", "TPS", "TFP", "ENR", "TCAS", "AIS", "RES"
}
EXCLUDED_DOCUMENT_PREFIXES = ["ACTU"]

# === Indexation / vectorisation ===
CHROMA_PATH = BASE_DIR / "chroma_bofip"
COLLECTION_NAME = "bofip_chunks"
EMBEDDINGS_PATH = "embeddings.pkl"
BATCH_SIZE = 75
TOP_K = 20
LEXICAL_WEIGHT = 0.7
MIN_SIMILARITY = 0.35

# === Prompts ===

# === Prompts RAG / Retriever ===
PROMPT_CLARIFY_QUESTION = (
    "Voici la question :\n{question}\n\n"
    "Ton r√¥le est de la reformuler pour qu'elle puisse √™tre utilis√©e dans un syst√®me RAG. "
    "Tu ne dois rien faire d'autre."
)

PROMPT_SUBQUESTIONS = (
    "Voici la question d‚Äôun utilisateur :\n{question}\n\n"
    "Ton r√¥le est de d√©composer cette question en 2 √† 4 sous-questions courtes et claires, "
    "chacune sur une seule ligne, sans explications ni puces inutiles.\n\n"
    "‚öñÔ∏è R√®gles :\n"
    "- Si la question concerne un th√®me sp√©cifique (ex. taxe sur les salaires, TVA, IS, imp√¥t sur le revenu, etc.), "
    "chaque sous-question doit explicitement rappeler ce th√®me.\n"
    "- Reformule les sous-questions pour qu‚Äôelles soient autonomes et informatives, sans d√©pendre du contexte implicite.\n"
    "- Si la question est d√©j√† simple, renvoie-la telle quelle.\n"
    "- Ne fournis aucune introduction ni commentaire, uniquement les sous-questions s√©par√©es par des retours √† la ligne.\n\n"
    "Sous-questions :\n"
    "Le d√©ficit provenant d‚Äôune activit√© professionnelle X est-il imputable sur le b√©n√©fice d‚Äôune autre activit√© Y au sein de la m√™me entreprise pour l‚Äôimp√¥t sur le revenu ?\n"
    "Quelles sont les r√®gles d‚Äôimputation des d√©ficits professionnels entre diff√©rentes activit√©s exerc√©es dans la m√™me structure soumise √† l‚Äôimp√¥t sur le revenu ?\n"
    "Le changement ou l‚Äôajout d‚Äôune activit√© (passage de l‚Äôactivit√© X √† Y) a-t-il une incidence sur la possibilit√© de reporter un d√©ficit ant√©rieur pour l‚Äôimp√¥t sur le revenu ?\n"
    "Existe-t-il des restrictions √† l‚Äôimputation des d√©ficits lorsque les activit√©s X et Y rel√®vent de cat√©gories fiscales diff√©rentes (BIC, BNC, BA) ?"
)


PROMPT_RERANK_LOCAL = (
    "Question : {question}\n\nTexte : {text}\n\n"
    "Note la pertinence de ce texte pour r√©pondre √† la question sur une √©chelle de 0 (inutile) √† 5 (tr√®s pertinent). "
    "R√©pond uniquement par un nombre."
)

PROMPT_RERANK = (
    "Tu es un expert-comptable charg√© de trouver les extraits les plus utiles pour r√©pondre √† une question. "
    "Ignore les extraits : hors sujet, trop vagues, ou qui abordent des dispositifs non √©voqu√©s dans la question. "
    "Ta r√©ponse doit contenir uniquement les num√©ros des extraits pertinents, tri√©s par ordre d√©croissant de pertinence (ex. : 4, 2, 1). "
    "Tu ne dois rien expliquer, ne rien reformuler, ne rien justifier."
)

PROMPT_ANSWER_HEADER = (
    "Tu es un expert-comptable charg√© de r√©pondre √† une question en fonction d'√©l√©ments communiqu√©s"
)

PROMPT_USER_ANSWER = (
    "Voici la question initiale pos√©e par l‚Äôutilisateur :\n {question_originale}\n\n"
    "Voici la reformulation de cette question par le syst√®me :\n {question_clarifiee}\n\n"
    "Voici les sous-questions g√©n√©r√©es pour structurer la recherche :\n{subquestions}\n\n"
    "Voici maintenant les extraits de textes issus de la recherche RAG "
    ":\n\n{context}\n\n"
    "=== Consignes multi-√©tapes ===\n"
    f"** 1√®re √©tape ** : En fonction de la question pos√©e et des extraits juridiques, s√©lectionne ceux qui r√©pondent totalement ou partiellement √† la question.\n"
    f"Format attendu : ne doit pas apparaitre dans la r√©ponse.\n"
    f"** 2√®me √©tape ** : V√©rifie que les r√©ponses s√©lectionn√©es sont coh√©rentes entre elles.\n"
    f"Format attendu : ne doit pas apparraitre dans la r√©ponse. \n"
    f"Si tu n'as pas assez d'√©l√©ments, r√©ponds : \"je n'ai pas assez d'√©l√©ments √† ma disposition pour r√©pondre\" et ne passe pas aux √©tapes suivantes.\n"
    f"** 3√®me √©tape ** : Formule un r√©sum√© complet des textes en citant les sources.\n"
    f"Format attendu : Sous-partie : Commence la section par un titre Markdown H2 : '## üìú **TEXTES JURIDIQUES APPLICABLES**'"
    f"Titre de l'article (en gras) \n R√©sum√© de l'article \n Source\n"
    f"** 4√®me √©tape ** : Explique comment ces textes et uniquement ces texte s‚Äôappliquent concr√®tement √† la question. Tu ne dois pas extrapoler\n"
    f"Format attendu : Sous-partie : Commence la section par un titre Markdown H2 : '## üîç **APPLICATION AU CAS D'ESP√àCE**'"
)

PROMPT_ANSWER = (
    "Tu es un expert-comptable charg√© de r√©pondre √† une question en fonction d'√©l√©ments communiqu√©s."
)

# === Filtre de m√©tadonn√©es (FILTER_TREE) ===
FILTER_TREE = {
    "fiscal": {
        "bofip": {
            "BIC": [
                "AMT", "BASE", "CESS", "CHAMP", "CHG", "DECLA", "DEF", "PDSTK",
                "PROCD", "PROV", "PTP", "PVMV", "RICI"
            ],
            "CVAE": ["BASE", "CHAMP", "DECLA", "LIEU", "LIQ", "PROCD"],
            "ENR": ["AVS", "DG", "DMTG", "DMTOI", "JOMI", "PTG", "TIM"],
            "IR": ["BASE", "CESS", "CHAMP", "DECLA", "DOMIC", "LIQ", "PROCD", "RICI"],
            "IS": [
                "BASE", "CESS", "CHAMP", "DECLA", "DEF", "FUS", "GEO", "GPE",
                "LIQ", "PROCD", "RICI"
            ],
            "RPPM": ["PVBMC", "PVBMI", "RCM"],
            "RSA": ["BASE", "CHAMP", "ES", "GEO", "GER", "PENS"],
            "TCA": [
                "AHJ", "AUTO", "BEU", "CAEA", "CAR", "CDP", "CPD", "CSR", "EHR", "EOL",
                "FIN", "FTPV", "IMP", "INPES", "MEDIC", "OCE", "PCT", "PJP", "PPA",
                "PRT", "PTV", "RPE", "RSAB", "RSD", "RSP", "SECUR", "SIPV", "TAB",
                "THA", "TPA", "TPC", "VLV"
            ],
            "TCAS": ["ASSUR", "AUT"],
            "TFP": [
                "AIFER", "ASSUR", "CAP", "GUF", "IFER", "MINES", "PYL",
                "RSB", "TASC", "TEM", "TSC", "TVS"
            ],
            "TPS": ["FPC", "PEEC", "TA", "TS"],
            "TVA": ["BASE", "CHAMP", "DECLA", "DED", "GEO", "IMM", "LIQ", "PROCD", "SECT"],
            "AIS": ["MOB", "CCN"],
            "RES": [""]
        }
    },
    "Juridique": {
        "Code des assurances": {
            "Le contrat": [""],
            "Assurances obligatoires": [""],
            "Les entreprises.": [""],
            "Organisations et r√©gimes particuliers d'assurance": [""],
            "Distributeurs d'assurances": [""]
        }
    },
    "Sociale": {
        "Convention collective": {
            "": [""]
        }
    },
    "G√©n√©rale": {
        "": {
            "": [""]
        }
    }
}

# ==========================================================
# === AJOUTS N√âCESSAIRES POUR APP.PY ===
# ==========================================================
LOG_LEVEL = os.getenv("LOG_LEVEL", "INFO")
DEFAULT_CHAT_MODEL = os.getenv("OPENAI_CHAT_MODEL", OPENAI_CHAT_MODEL)

# === Param√®tres du pipeline RAG / Retriever ===
TOP_K_SUBQUESTION = 5        # Nombre de r√©sultats par sous-question
TOP_K_FINAL = 15             # Nombre total apr√®s fusion
MAX_SUBQUERIES = 4           # Nombre max de sous-questions
PREFETCH_K = 10              # Pr√©chargement Qdrant (dense + sparse)
BIG_CHUNKS_JSON_PATH = os.getenv(
    "BIG_CHUNKS_JSON_PATH",
    str(BASE_DIR / "data" / "processed" / "bofip_chunks_bs.json")
)

# === Logs ===
LOG_DIR = BASE_DIR / "logs"